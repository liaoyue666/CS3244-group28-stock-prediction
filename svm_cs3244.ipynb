{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b5a27c6-f796-4ec7-b16e-e531f82a9dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score, brier_score_loss, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac59525e-9e4e-4a20-8878-851aa03a6824",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"combined_cleaned.csv\"\n",
    "LOOKBACK = 1\n",
    "HIGH_VOL_Q = 0.5\n",
    "THRESHOLDS = [0.40, 0.45, 0.50, 0.55, 0.60]\n",
    "\n",
    "BASE_FEATURES = [\"log_return\",\"lag1\",\"lag3\",\"lag5\",\"MA5\",\"MA20\",\"vol_5\",\"Volume\",\"rel_vol\",\"regime_high_vol\"]\n",
    "CANDIDATE_FEATURES = [\"log_return\",\"lag1\",\"lag3\",\"lag5\",\"MA5\",\"MA20\",\"vol_5\",\"Volume\",\"rel_vol\",\"regime_high_vol\",\n",
    "    \"MA_diff\",\"return_over_vol\",\"volume_spike\",\"log_return_z_cs\",\"MA5_z_cs\",\"MA20_z_cs\",\"vol_5_z_cs\",\"Volume_z_cs\",\"rel_vol_z_cs\",\"log_return_rank_cs\",\"vol_5_rank_cs\",\"Volume_rank_cs\"]\n",
    "\n",
    "SVM_C_LINEAR = 1.0\n",
    "SVM_C_RBF = 1.0\n",
    "SVM_GAMMA_RBF = 0.01\n",
    "def load_and_basic_clean(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], dayfirst=True, errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"Date\"]).copy()\n",
    "    df = df.sort_values([\"Ticker\", \"Date\"])\n",
    "    df = df.drop_duplicates(subset=[\"Ticker\", \"Date\"])\n",
    "    return df\n",
    "\n",
    "def ensure_log_return(df):\n",
    "    df = df.copy()\n",
    "    if \"log_return\" not in df.columns:\n",
    "        df[\"log_return\"] = (\n",
    "            np.log(df[\"Close\"]) - np.log(df.groupby(\"Ticker\")[\"Close\"].shift(1))\n",
    "        )\n",
    "    return df\n",
    "\n",
    "def add_market_regime(df, vol_window=20, min_periods=10):\n",
    "    df = df.copy()\n",
    "    mkt_ret = (\n",
    "        df.groupby(\"Date\")[\"log_return\"]\n",
    "          .mean()\n",
    "          .sort_index()\n",
    "    )\n",
    "    mkt_vol = mkt_ret.rolling(window=vol_window, min_periods=min_periods).std()\n",
    "    vol_median = mkt_vol.median()\n",
    "    df[\"market_vol\"] = df[\"Date\"].map(mkt_vol)\n",
    "    df[\"regime_high_vol\"] = (df[\"market_vol\"] > vol_median).astype(int)\n",
    "    return df\n",
    "\n",
    "def add_realized_vol_5(df, horizon=5):    \n",
    "    df = df.copy()\n",
    "    df[\"realized_vol_5\"] = np.nan\n",
    "    for ticker, g in df.groupby(\"Ticker\"):\n",
    "        idx = g.index\n",
    "        r = g[\"log_return\"]\n",
    "        r_sq = r ** 2\n",
    "        acc = None\n",
    "        for i in range(1, horizon + 1):\n",
    "            shifted = r_sq.shift(-i)\n",
    "            acc = shifted if acc is None else acc + shifted\n",
    "        rv5 = np.sqrt(acc / horizon)\n",
    "        df.loc[idx, \"realized_vol_5\"] = rv5\n",
    "    return df\n",
    "\n",
    "def add_interaction_features(df):\n",
    "    df = df.copy()\n",
    "    if \"MA5\" in df.columns and \"MA20\" in df.columns:\n",
    "        df[\"MA_diff\"] = df[\"MA5\"] - df[\"MA20\"]\n",
    "    if \"log_return\" in df.columns and \"vol_5\" in df.columns:\n",
    "        eps = 1e-6\n",
    "        df[\"return_over_vol\"] = df[\"log_return\"] / (df[\"vol_5\"].replace(0, np.nan) + eps)\n",
    "    if \"Volume\" in df.columns:\n",
    "        df[\"volume_spike\"] = np.nan\n",
    "        for ticker, g in df.groupby(\"Ticker\"):\n",
    "            idx = g.index\n",
    "            vol = g[\"Volume\"]\n",
    "            vol_ma20 = vol.rolling(window=20, min_periods=5).mean()\n",
    "            df.loc[idx, \"volume_spike\"] = vol / (vol_ma20.replace(0, np.nan))\n",
    "    return df\n",
    "\n",
    "def add_cross_sectional_features(df):\n",
    "    df = df.copy()\n",
    "    cs_cols_for_z = [\"log_return\",\"MA5\",\"MA20\",\"vol_5\",\"Volume\",\"rel_vol\"]\n",
    "    for col in cs_cols_for_z:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        group = df.groupby(\"Date\")[col]\n",
    "        mean = group.transform(\"mean\")\n",
    "        std = group.transform(\"std\").replace(0, np.nan)\n",
    "        z_name = f\"{col}_z_cs\"\n",
    "        df[z_name] = (df[col] - mean) / std\n",
    "        df[z_name] = df[z_name].fillna(0.0)\n",
    "    rank_cols = [\"log_return\", \"vol_5\", \"Volume\"]\n",
    "    for col in rank_cols:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        r_name = f\"{col}_rank_cs\"\n",
    "        df[r_name] = (\n",
    "            df.groupby(\"Date\")[col]\n",
    "              .rank(pct=True)\n",
    "        )\n",
    "    return df\n",
    "\n",
    "def get_feature_columns(df):\n",
    "    feature_cols = [c for c in CANDIDATE_FEATURES if c in df.columns]\n",
    "    if not feature_cols:\n",
    "        raise ValueError(\"No candidate features found in dataframe.\")\n",
    "    df = df.dropna(subset=feature_cols).copy()\n",
    "    feature_cols = [c for c in feature_cols if c in df.columns]\n",
    "    return df, feature_cols\n",
    "\n",
    "def define_folds():\n",
    "    folds = [\n",
    "        {\n",
    "            \"name\": \"fold1\",\n",
    "            \"train_start\": \"2009-01-01\",\n",
    "            \"train_end\":   \"2013-12-31\",\n",
    "            \"val_start\":   \"2014-01-01\",\n",
    "            \"val_end\":     \"2014-12-31\",\n",
    "            \"test_start\":  \"2015-01-01\",\n",
    "            \"test_end\":    \"2015-12-31\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"fold2\",\n",
    "            \"train_start\": \"2009-01-01\",\n",
    "            \"train_end\":   \"2014-12-31\",\n",
    "            \"val_start\":   \"2015-01-01\",\n",
    "            \"val_end\":     \"2015-12-31\",\n",
    "            \"test_start\":  \"2016-01-01\",\n",
    "            \"test_end\":    \"2016-12-31\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"fold3\",\n",
    "            \"train_start\": \"2009-01-01\",\n",
    "            \"train_end\":   \"2015-12-31\",\n",
    "            \"val_start\":   \"2016-01-01\",\n",
    "            \"val_end\":     \"2016-12-31\",\n",
    "            \"test_start\":  \"2017-01-01\",\n",
    "            \"test_end\":    \"2017-12-31\",\n",
    "        },\n",
    "    ]\n",
    "    for f in folds:\n",
    "        for k in [\"train_start\",\"train_end\",\"val_start\",\"val_end\",\"test_start\",\"test_end\"]:\n",
    "            f[k] = pd.to_datetime(f[k])\n",
    "    return folds\n",
    "\n",
    "def build_single_day_data(df, feature_cols):\n",
    "    \"\"\"\n",
    "    Transforms the DataFrame into NumPy arrays of single-day features.\n",
    "    X: (N, d), rv5: (N,), dates: (N,), tickers: (N,)\n",
    "    \"\"\"\n",
    "    df = df.sort_values([\"Ticker\", \"Date\"])\n",
    "    X = df[feature_cols].values       \n",
    "    rv = df[\"realized_vol_5\"].values \n",
    "    dates = df[\"Date\"].values         \n",
    "    tickers = df[\"Ticker\"].values\n",
    "    valid_mask = ~np.isnan(rv)\n",
    "    return X[valid_mask], rv[valid_mask], dates[valid_mask], tickers[valid_mask]\n",
    "\n",
    "def evaluate_metrics(y_true, y_pred, p_pred):\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(y_true, p_pred)\n",
    "    except ValueError:\n",
    "        roc_auc = np.nan\n",
    "    try:\n",
    "        pr_auc = average_precision_score(y_true, p_pred)\n",
    "    except ValueError:\n",
    "        pr_auc = np.nan\n",
    "    brier = brier_score_loss(y_true, p_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"pr_auc\": pr_auc,\n",
    "        \"brier\": brier,\n",
    "        \"tn\": int(tn),\n",
    "        \"fp\": int(fp),\n",
    "        \"fn\": int(fn),\n",
    "        \"tp\": int(tp),\n",
    "    }\n",
    "\n",
    "def tune_threshold(y_val, p_val, thresholds):\n",
    "    best_tau = 0.5\n",
    "    best_acc = -1.0\n",
    "    for tau in thresholds:\n",
    "        preds = (p_val >= tau).astype(int)\n",
    "        acc = accuracy_score(y_val, preds)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_tau = tau\n",
    "    return best_tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a222111-beba-4717-9bd0-acb796f23611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_fold_linear_svm(X, rv5, dates, feature_cols, fold):\n",
    "    train_mask = (dates >= fold[\"train_start\"]) & (dates <= fold[\"train_end\"])\n",
    "    val_mask   = (dates >= fold[\"val_start\"])   & (dates <= fold[\"val_end\"])\n",
    "    test_mask  = (dates >= fold[\"test_start\"])  & (dates <= fold[\"test_end\"])\n",
    "\n",
    "    X_train, rv_train = X[train_mask], rv5[train_mask]\n",
    "    X_val,   rv_val   = X[val_mask],   rv5[val_mask]\n",
    "    X_test,  rv_test  = X[test_mask],  rv5[test_mask]\n",
    "\n",
    "    if X_train.shape[0] == 0 or X_val.shape[0] == 0 or X_test.shape[0] == 0:\n",
    "        return None, None\n",
    "\n",
    "    thr = np.quantile(rv_train, HIGH_VOL_Q)\n",
    "    y_train = (rv_train >= thr).astype(int)\n",
    "    y_val   = (rv_val   >= thr).astype(int)\n",
    "    y_test  = (rv_test  >= thr).astype(int)\n",
    "    majority_label = 1 if y_train.mean() >= 0.5 else 0\n",
    "    baseline_acc_test = (y_test == majority_label).mean()\n",
    "    \n",
    "    # Model: Linear Kernel\n",
    "    model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        # Linear kernel allows extracting feature weights (coefficients_)\n",
    "        ('svm', SVC(C=SVM_C_LINEAR, kernel='linear', probability=True, random_state=42))\n",
    "    ])\n",
    "\n",
    "    print(f\"\\n===== Training {fold['name']} (Linear SVM) =====\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Extract Feature Weights and Support Vector Count\n",
    "    svm_step = model.named_steps['svm']\n",
    "    linear_weights = svm_step.coef_[0]\n",
    "    sv_count = svm_step.n_support_.sum()\n",
    "    \n",
    "    p_val = model.predict_proba(X_val)[:, 1]\n",
    "    p_test = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    best_tau = tune_threshold(y_val, p_val, THRESHOLDS)\n",
    "    y_pred_test = (p_test >= best_tau).astype(int)\n",
    "    \n",
    "    metrics = evaluate_metrics(y_test, y_pred_test, p_test)\n",
    "    \n",
    "    result = {\n",
    "        \"fold\": fold[\"name\"],\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred_test),\n",
    "        \"baseline_acc\": baseline_acc_test,\n",
    "        \"sv_count\": int(sv_count),\n",
    "        **metrics\n",
    "    }\n",
    "    \n",
    "    # 提取权重和前10个最重要特征\n",
    "    weight_df = pd.DataFrame({'Feature': feature_cols, 'Weight': linear_weights})\n",
    "    top_10_weights = weight_df.reindex(weight_df['Weight'].abs().sort_values(ascending=False).index).head(10)\n",
    "    \n",
    "    return result, top_10_weights\n",
    "\n",
    "# RBF SVM\n",
    "def train_one_fold_rbf_svm(X, rv5, dates, feature_cols, fold):\n",
    "    train_mask = (dates >= fold[\"train_start\"]) & (dates <= fold[\"train_end\"])\n",
    "    val_mask   = (dates >= fold[\"val_start\"])   & (dates <= fold[\"val_end\"])\n",
    "    test_mask  = (dates >= fold[\"test_start\"])  & (dates <= fold[\"test_end\"])\n",
    "\n",
    "    X_train, rv_train = X[train_mask], rv5[train_mask]\n",
    "    X_val,   rv_val   = X[val_mask],   rv5[val_mask]\n",
    "    X_test,  rv_test  = X[test_mask],  rv5[test_mask]\n",
    "\n",
    "    if X_train.shape[0] == 0 or X_val.shape[0] == 0 or X_test.shape[0] == 0:\n",
    "        return None\n",
    "\n",
    "    thr = np.quantile(rv_train, HIGH_VOL_Q)\n",
    "    y_train = (rv_train >= thr).astype(int)\n",
    "    y_val   = (rv_val   >= thr).astype(int)\n",
    "    y_test  = (rv_test  >= thr).astype(int)\n",
    "    \n",
    "    majority_label = 1 if y_train.mean() >= 0.5 else 0\n",
    "    baseline_acc_test = (y_test == majority_label).mean()\n",
    "\n",
    "    # Model: RBF Kernel (Tests robustness to high-dimensional separation)\n",
    "    model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svm', SVC(C=SVM_C_RBF, kernel='rbf', gamma=SVM_GAMMA_RBF, probability=True, random_state=42))\n",
    "    ])\n",
    "\n",
    "    print(f\"\\n===== Training {fold['name']} (RBF SVM - High-Dimensional Separation Test) =====\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    p_val = model.predict_proba(X_val)[:, 1]\n",
    "    p_test = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Extract Support Vector Count (for RBF analysis)\n",
    "    sv_count = model.named_steps['svm'].n_support_.sum()\n",
    "    \n",
    "    best_tau = tune_threshold(y_val, p_val, THRESHOLDS)\n",
    "    y_pred_test = (p_test >= best_tau).astype(int)\n",
    "    \n",
    "    metrics = evaluate_metrics(y_test, y_pred_test, p_test)\n",
    "    \n",
    "    result = {\n",
    "        \"fold\": fold[\"name\"],\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred_test),\n",
    "        \"baseline_acc\": baseline_acc_test,\n",
    "        \"sv_count\": int(sv_count),\n",
    "        **metrics\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c75ca630-980a-4ab3-ba5a-92824916ab05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data built: 10806 samples, features=22\n",
      "\n",
      "===== Training fold1 (Linear SVM) =====\n",
      "\n",
      "===== Training fold2 (Linear SVM) =====\n",
      "\n",
      "===== Training fold3 (Linear SVM) =====\n",
      "\n",
      "\n",
      "=============== LINEAR SVM RESULTS (Kernel: Linear) ===============\n",
      "Interpretation: Measures linear separability and provides feature weights.\n",
      "Per-fold Metrics:\n",
      "     fold  accuracy   roc_auc        f1  sv_count\n",
      "0  fold1  0.572391  0.607145  0.015504      1737\n",
      "1  fold2  0.713333  0.649006  0.472393      2176\n",
      "2  fold3  0.878968  0.748043  0.666667      2685\n",
      "\n",
      "Average ROC-AUC (Linear): 0.668064429080868\n",
      "\n",
      "Top 10 Feature Weights (Fold 3 Example):\n",
      "            Feature    Weight\n",
      "16       vol_5_z_cs -1.281267\n",
      "15        MA20_z_cs -0.915006\n",
      "20    vol_5_rank_cs  0.399082\n",
      "21   Volume_rank_cs -0.235659\n",
      "6             vol_5  0.184144\n",
      "9   regime_high_vol  0.123826\n",
      "13  log_return_z_cs  0.107508\n",
      "5              MA20 -0.092386\n",
      "4               MA5 -0.091660\n",
      "17      Volume_z_cs  0.076836\n",
      "\n",
      "===== Training fold1 (RBF SVM - High-Dimensional Separation Test) =====\n",
      "\n",
      "===== Training fold2 (RBF SVM - High-Dimensional Separation Test) =====\n",
      "\n",
      "===== Training fold3 (RBF SVM - High-Dimensional Separation Test) =====\n",
      "\n",
      "\n",
      "=============== RBF SVM RESULTS (Kernel: RBF) ===============\n",
      "Interpretation: Measures robustness to non-linear separation (Project Goal).\n",
      "Per-fold Metrics:\n",
      "     fold  accuracy   roc_auc        f1  sv_count\n",
      "0  fold1  0.646465  0.645357  0.435484      1738\n",
      "1  fold2  0.710000  0.700244  0.502857      2166\n",
      "2  fold3  0.886905  0.802230  0.704663      2669\n",
      "\n",
      "Average ROC-AUC (RBF): 0.7159433269904368\n",
      "\n",
      "Average Performance Comparison:\n",
      "Linear AUC                 0.668064\n",
      "RBF AUC                    0.715943\n",
      "Linear SV Count Mean    2199.333333\n",
      "RBF SV Count Mean       2191.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(    fold  accuracy  baseline_acc  sv_count  precision    recall        f1  \\\n",
       " 0  fold1  0.572391      0.427609      1737   0.500000  0.007874  0.015504   \n",
       " 1  fold2  0.713333      0.386667      2176   0.819149  0.331897  0.472393   \n",
       " 2  fold3  0.878968      0.216270      2685   0.824324  0.559633  0.666667   \n",
       " \n",
       "     roc_auc    pr_auc     brier   tn  fp   fn  tp  \n",
       " 0  0.607145  0.514037  0.276594  338   2  252   2  \n",
       " 1  0.649006  0.572791  0.211763  351  17  155  77  \n",
       " 2  0.748043  0.616272  0.169786  382  13   48  61  ,\n",
       "     fold  accuracy  baseline_acc  sv_count  precision    recall        f1  \\\n",
       " 0  fold1  0.646465      0.427609      1738   0.686441  0.318898  0.435484   \n",
       " 1  fold2  0.710000      0.386667      2166   0.745763  0.379310  0.502857   \n",
       " 2  fold3  0.886905      0.216270      2669   0.809524  0.623853  0.704663   \n",
       " \n",
       "     roc_auc    pr_auc     brier   tn  fp   fn  tp  \n",
       " 0  0.645357  0.566484  0.250184  303  37  173  81  \n",
       " 1  0.700244  0.618851  0.202625  338  30  144  88  \n",
       " 2  0.802230  0.649872  0.135997  379  16   41  68  )"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_svm_comparison():\n",
    "    df = load_and_basic_clean(DATA_PATH)\n",
    "    df = ensure_log_return(df)\n",
    "    df = add_market_regime(df)\n",
    "    df = add_realized_vol_5(df, horizon=5)\n",
    "    df = add_interaction_features(df)\n",
    "    df = add_cross_sectional_features(df)\n",
    "    df = df.dropna(subset=[\"realized_vol_5\"]).copy()\n",
    "    df, feature_cols = get_feature_columns(df)\n",
    "    X, rv5, dates, tickers = build_single_day_data(df, feature_cols)\n",
    "    print(f\"Data built: {X.shape[0]} samples, features={X.shape[1]}\")\n",
    "    folds = define_folds()\n",
    "    \n",
    "    linear_results = []\n",
    "    all_weights = {}\n",
    "\n",
    "    for fold in folds:\n",
    "        res, weights_df = train_one_fold_linear_svm(X, rv5, dates, feature_cols, fold)\n",
    "        if res is not None:\n",
    "            linear_results.append(res)\n",
    "            all_weights[fold['name']] = weights_df\n",
    "            \n",
    "    linear_df = pd.DataFrame(linear_results)\n",
    "    \n",
    "    print(\"\\n\\n=============== LINEAR SVM RESULTS (Kernel: Linear) ===============\")\n",
    "    print(\"Interpretation: Measures linear separability and provides feature weights.\")\n",
    "    print(\"Per-fold Metrics:\\n\", linear_df[[\"fold\", \"accuracy\", \"roc_auc\", \"f1\", \"sv_count\"]])\n",
    "    print(\"\\nAverage ROC-AUC (Linear):\", linear_df[\"roc_auc\"].mean())\n",
    "    print(\"\\nTop 10 Feature Weights (Fold 3 Example):\")\n",
    "    if 'fold3' in all_weights:\n",
    "        print(all_weights['fold3'])\n",
    "    \n",
    "    rbf_results = []\n",
    "\n",
    "    for fold in folds:\n",
    "        res = train_one_fold_rbf_svm(X, rv5, dates, feature_cols, fold)\n",
    "        if res is not None:\n",
    "            rbf_results.append(res)\n",
    "            \n",
    "    rbf_df = pd.DataFrame(rbf_results)\n",
    "    \n",
    "    print(\"\\n\\n=============== RBF SVM RESULTS (Kernel: RBF) ===============\")\n",
    "    print(\"Interpretation: Measures robustness to non-linear separation (Project Goal).\")\n",
    "    print(\"Per-fold Metrics:\\n\", rbf_df[[\"fold\", \"accuracy\", \"roc_auc\", \"f1\", \"sv_count\"]])\n",
    "    print(\"\\nAverage ROC-AUC (RBF):\", rbf_df[\"roc_auc\"].mean())\n",
    "    print(\"\\nAverage Performance Comparison:\")\n",
    "    comparison = {\n",
    "        \"Linear AUC\": linear_df[\"roc_auc\"].mean(),\n",
    "        \"RBF AUC\": rbf_df[\"roc_auc\"].mean(),\n",
    "        \"Linear SV Count Mean\": linear_df[\"sv_count\"].mean(),\n",
    "        \"RBF SV Count Mean\": rbf_df[\"sv_count\"].mean()\n",
    "    }\n",
    "    print(pd.Series(comparison))\n",
    "    \n",
    "    return linear_df, rbf_df\n",
    "\n",
    "run_svm_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31a6cb3-ba58-47ab-af38-b10d4f43b8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
